{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2263538",
   "metadata": {},
   "source": [
    "# Introduction to Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eebcd57",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<Strong>Objectives</strong>\n",
    "\n",
    "- Become familiar with the Pandas data analysis library in python\n",
    "- Read data into pandas DataFrames from files\n",
    "- Manipulate data in the DataFrame\n",
    "- Export data as CSV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6f36fa",
   "metadata": {},
   "source": [
    "Pandas is a flexible open-source data analysis and manipulation library for Python. It provides data structures in series and DataFrames. A series is like a list and a DataFrame is like a spreadsheet. The key is that this library allows users to easily load, explore, clean, transform and analyzed structured data. It is widely used in data science, machine learning and statitical analysis.\n",
    "\n",
    "This activity is intended to give you a brief overview of DataFrames and introduce you to pandas concepts we are using in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef858e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pandas library \n",
    "# the pandas community as agreed that the alias for pandas is 'pd'. \n",
    "# Loading pandas with this alias allows us to use its functions and classes with a shorter name.\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d9961d",
   "metadata": {},
   "source": [
    "Much of the data we will be using is availabe as comma separated values files from PubChem or other resources. Pandas has the ability to read in csv data either locally from a downloaded file or as a request if we know the source of the file. In the code cell below, we will download the <a href = https://pubchem.ncbi.nlm.nih.gov/periodic-table/> periodic table from PubChem </a> and store it into a DataFrame variable call `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e26fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the periodic table data from a URL into a pandas DataFrame. \n",
    "# We do not need to use the `requests` library here because pandas can directly read from URLs.\n",
    "url = \"https://pubchem.ncbi.nlm.nih.gov/rest/pug/periodictable/CSV\" #url for the periodic table data in CSV format\n",
    "df = pd.read_csv(url) # read the CSV data from the URL into a pandas DataFrame\n",
    "df # display the DataFrame to see its contents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb0c327",
   "metadata": {},
   "source": [
    "Notice that the DataFrame output indicates it has 118 rows and 17 columns. There are a few ways to get information about rows and columns in our DataFrame(named `df`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6247bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(len(df))\n",
    "print(df.shape[0])  \n",
    "print(df.shape[1])  \n",
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279d2aae",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<strong>Check your understanding</strong>\n",
    "\n",
    "Write comments next to each line in the code above to indicate what the code is doing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49b683d",
   "metadata": {},
   "source": [
    "Run the next four code cells to explore the columns property and head, tail and info methods of a DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5359f4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns # display the columns of the DataFrame to understand its structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8eed6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3) # display the first 3 rows of the DataFrame to get a glimpse of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c9528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(5)  # display the last 5 rows of the DataFrame to see the end of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a7b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() # display information about the DataFrame, such as the number of entries, column names, and data types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfdbb29",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<strong>Check your understanding</strong>\n",
    "\n",
    "* When displaying a DataFrame, what is the default display?\n",
    "* If you only want to see the first 4 lines of the DataFrame, what command would you type?\n",
    "* If you want to see the last line only of the DataFrame, what command would you type?\n",
    "* Why is hydrogen, atomic number 1, listed as row 0?\n",
    "* Why might some of the data be null for these elements?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1654ea9d",
   "metadata": {},
   "source": [
    "### Accessing Subsets of Data in the DataFrame\n",
    "Now that our data is in a DataFrame, we can access a subset of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4564e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the row with index 17 to see the details of the element at that index\n",
    "df.loc[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2021ede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will show the symbol of the element at index 17\n",
    "df.loc[17, \"Symbol\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e292990a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code cell will display the name and Atomic Radius of the element at index 17\n",
    "# it uses the `loc` method to access specific rows and columns in the DataFrame\n",
    "# this require the name of the columns to be specified as a list\n",
    "df.loc[17, [\"Name\", \"AtomicRadius\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5494b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the name and atomic radius of the element at index 17 using column indexing\n",
    "# it uses the `iloc` method to access specific rows and columns by their integer index\n",
    "# you do not need to specify the column names, just their integer positions\n",
    "# This can be useful when you know the position of the columns but not their names or the names are long.\n",
    "df.iloc[17, [0, 7]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2800f4",
   "metadata": {},
   "source": [
    "Sometimes we want to have a subset of the data. This is achieved by identifying which columns we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6edcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Name\", \"GroupBlock\"]].head(3) # display the first 3 rows of the \"Name\" and \"GroupBlock\" columns    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1772c25",
   "metadata": {},
   "source": [
    "We can also filter the data when we only want a subset of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41412d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"AtomicNumber\"] < 10.0 ]# display the rows where the \"AtomicNumber\" is less than 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6f5219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display rows where AtomicNumber is greater than 10 and less than 20\n",
    "df[(df[\"AtomicNumber\"] > 10) & (df[\"AtomicNumber\"] < 20)] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f456fc0",
   "metadata": {},
   "source": [
    "Notice in the series called GroupBlock has repeating values. If we want to display how many different values are in that column, we can identify how many are `.unique`, and then show how many elements in the DataFrame are classified as Noble gasses using different methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be408815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the unique values in the \"GroupBlock\" column\n",
    "print(\"Unique values in 'GroupBlock':\")\n",
    "print(df.GroupBlock.unique()) \n",
    "print()\n",
    "# display the total count of unique values in the \"GroupBlock\" column\n",
    "print(\"Total unique values in 'GroupBlock':\")\n",
    "print(df[\"GroupBlock\"].nunique()) # nunique(): Returns the count of unique values.\n",
    "print(len(df[\"GroupBlock\"].unique())) # len(): Returns the count of unique values in the Series.\n",
    "print()\n",
    "# display the total count of rows where the \"GroupBlock\" is \"Noble Gas\" using the `shape` attribute\n",
    "print(\"Total count of rows where 'GroupBlock' is 'Noble gas':\")\n",
    "print(df[df[\"GroupBlock\"] == \"Noble gas\"].shape[0])\n",
    "# display the total count of rows where the \"GroupBlock\" is \"Noble Gas\" using the length function\n",
    "print(len(df[df[\"GroupBlock\"] == \"Noble gas\"]))\n",
    "# display the total count of rows where the \"GroupBlock\" is \"Noble Gas\" using the .sum()` method\n",
    "print(df[\"GroupBlock\"].eq(\"Noble gas\").sum())\n",
    "print()\n",
    "\n",
    "#create a list of elements that are Noble Gases\n",
    "noble_gases = df[df[\"GroupBlock\"] == \"Noble gas\"][\"Name\"].tolist()\n",
    "# display the list of Noble Gases\n",
    "print(\"The noble gases are:\", noble_gases)\n",
    "# display the DataFrame filtered to show only rows where the \"GroupBlock\" is \"Noble gas\"\n",
    "df[(df[\"GroupBlock\"].eq(\"Noble gas\"))] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9db7818",
   "metadata": {},
   "source": [
    "Sometimes we find that there is data in columns that may be irrelevant to your data analysis. This column can be removed using the `.drop()` method. Looking at the data in the DataFrame above, we probably don't need CPKHexColor column. Let's remove that data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f52443",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('CPKHexColor', axis=1)  # drop the 'CPKHexColor' column from the DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e72cdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090492a3",
   "metadata": {},
   "source": [
    "### Sorting Data\n",
    "Pandas provides the `sort_values` method to sort data in your series. The default is to sort by ascending value in a column. We can use a keyword argument in the `sort_values` method to set optional parameters. In this case using <code><i>ascending</i>=False</code> sorts in desending order and <code><i>ascending</i>=True</code> sorts in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b31a11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5058ac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the DataFrame by \"AtomicNumber\" in descending order (acending=True will sort in ascending order)\n",
    "df.sort_values(by=\"AtomicNumber\", ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd7a3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=\"AtomicRadius\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed24f5cd",
   "metadata": {},
   "source": [
    "Notice in the above DataFrame display that after sorting by Atomic Radius, the tail 5 entries have `NaN` displayed. This is Not a Number (NaN) and in pandas represents missing data. \n",
    "\n",
    "If you want to identify NaN values, you can use the `isna()` method. Identifying the NaN values then allows us to remove them from the DataFrame. This is accomplished through the `dropna()` method. It drops any rows that contain `NaN` values. This looks for values that are `False` or `not True`. \n",
    "\n",
    "Alternatively, you could identify only `True` values by using the `notna()` method.\n",
    "\n",
    "In the following code cells identify which Rows have NaN values for Atomic Radius and then we will create a new DataFrame that has only Atomic Number and Atomic Radii without with NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eb38d0",
   "metadata": {},
   "outputs": [],
   "source": [
    " # display the number of NaN values in each column\n",
    "print(df.isna().sum()) \n",
    "print()\n",
    "# display the number of NaN values in only the \"Atomic Radius\" column\n",
    "print(\"The number of rows where Atomic Radius is NaN is:\",df.AtomicRadius.isna().sum()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495a4639",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(df.notna().sum())  # display the number of non-NaN values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2868d152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify and print all rows where AtomicRadius is NaN\n",
    "df[df['AtomicRadius'].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7f6b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with AtomicNumber and AtomicRadius, dropping rows where AtomicRadius is NaN\n",
    "df_atomic_radius_dropped = df[['AtomicNumber', 'AtomicRadius']].dropna(subset=['AtomicRadius'])\n",
    "df_atomic_radius_dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b966e75",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<Strong>Check Your Understanding</strong>\n",
    "\n",
    "In the cell block below, write code to generate a new DataFrame called <strong>df_drop_density</strong> that only has Names and Density values that have values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea95cb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your Check your Understanding code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c2a2f1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary >Solution</summary>\n",
    "<div style=\"text-align: left\">\n",
    "\n",
    "<pre style=\"color: black;\">\n",
    "df_drop_density = df[['Name', 'Density']].dropna(subset=['Density'])\n",
    "df_drop_density\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc7010e",
   "metadata": {},
   "source": [
    "### Working with data files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfdd5e0",
   "metadata": {},
   "source": [
    "Once you have maninpulated your data, it is a good idea to save this data as a comma separated values (.csv) file. This can be accessed later and has all of your data cleaned for the next project. For example, you now have a DataFrame that is just atomic number and atomic radius. You can write that data to a new csv file using the `to_csv()` method.\n",
    "\n",
    "Your DataFrame not only has columns(series) of data, but also index numbers. Those index numbers may not be meaningful in other contexts. When you save the data as csv, you can choose to include the index value. The default is to include index, but setting an argument to index=False, you will exclude the index an only include the column data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f290d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atomic_radius_dropped.to_csv('atomic_radius.csv') \n",
    "df_atomic_radius_dropped.to_csv('atomic_radius_noindex.csv', index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b649c428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63d16217",
   "metadata": {},
   "source": [
    "You can also upload that data from your file into a new DataFrame. One thing to note is that you need to specify its location. In this example, you wrote the csv file into the same directory as the original jupyter notebook, so you don't need to specify where it is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab685bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fromfile = pd.read_csv(\"atomic_radius_noindex.csv\")\n",
    "df_fromfile.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136102cf",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<Strong>Check Your Understanding</strong>\n",
    "\n",
    "You have a DataFrame that loaded in your saved atomic_radius_noindex.csv file. \n",
    "* Load the atomic_radius.csv file into another DataFrame called df_index.\n",
    "* Display the first three rows of data.\n",
    "* If there is an unnamed column, remove that column from df_index in another code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e86afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049c1ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2348af7b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary >Solution</summary>\n",
    "<div style=\"text-align: left\">\n",
    "\n",
    "<pre style=\"color: black;\">\n",
    "df_index = pd.read_csv(\"atomic_radius.csv\")\n",
    "df_index.head(3) \n",
    "</pre>\n",
    "<br> \n",
    "New Code cell\n",
    "<pre style=\"color: black;\">\n",
    "df_index = df_index.drop(columns=[\"Unnamed: 0\"], axis =1) \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fdab70",
   "metadata": {},
   "source": [
    "In the next notebook, we will be accessing data from a website. The data is provided as space delimited file meaning the column data is separted by spaces rather than commas. When we load the data we can specify the separation of data with the `sep = \" \"` argument.\n",
    "\n",
    "The data from this website also does not have column names for the data. We can specify those names as we bring the data in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1726fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['smiles','dat', 'id']\n",
    "df_act = pd.read_csv(\"https://dude.docking.org/targets/aa2ar/actives_final.ism\", sep=\" \", names=colnames)\n",
    "df_act\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90362843",
   "metadata": {},
   "source": [
    "Once we have a DataFrame, we can also save that DataFrame locally as a csv file to load later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd2004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the DataFrame to a CSV file named 'aa2ar_actives.csv'\n",
    "df_act.to_csv('aa2ar_actives.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cb0e8d",
   "metadata": {},
   "source": [
    "### Joining two DataFrames\n",
    "\n",
    "A common operation when working with data is joining two DataFrames together. This is especially useful when information about a common set of molecules is stored in two different datasets. For example, you might have one DataFrame that has SMILES strings and names and a second that has names and experimental data. The `.join()` method combines the two DataFrames together using an index value that allows you to analyze all relevant data in a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a752705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame1 = pd.DataFrame({\n",
    "    'xLogP3': [1.2, 3.5, 3.3],\n",
    "    'MolecularWeight': [180.16, 206.28, 230.26]\n",
    "}, index=['Aspirin', 'Ibuprofen', 'Naproxen'])\n",
    "\n",
    "DataFrame2 = pd.DataFrame({\n",
    "    'TPSA': [63.6, 37.3, 46.5],\n",
    "    'SMILES': ['CC(=O)OC1=CC=CC=C1C(=O)O', 'CC(C)CC1=CC=C(C=C1)C(C)C(=O)O', 'C[C@@H](C1=CC2=C(C=C1)C=C(C=C2)OC)C(=O)O']\n",
    "}, index=['Aspirin', 'Ibuprofen', 'Naproxen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78326ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since these are small DataFrames, we can display them side by side in a Jupyter Notebook using HTML\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "df1_html = DataFrame1.to_html()\n",
    "df2_html = DataFrame2.to_html()\n",
    "\n",
    "display(HTML(f\"\"\"\n",
    "<table>\n",
    "<tr>\n",
    "    <th><H3>DataFrame1</H3></th>\n",
    "    <th><H3>DataFrame2</H3></th>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>{df1_html}</td>\n",
    "    <td style=\"padding-left: 30px;\">{df2_html}</td>\n",
    "</tr>\n",
    "</table>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e854d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFramecombined = DataFrame1.join(DataFrame2)\n",
    "DataFramecombined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d05a7ad",
   "metadata": {},
   "source": [
    "Pandas is quite powerful and we have only scratched the surface. To get more savvy with pandas, you can access tutorials available at https://pandas.pydata.org/pandas-docs/version/0.15/tutorials.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed57d44",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<center><H1>Homework</H1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4dec0a",
   "metadata": {},
   "source": [
    "Familiarize yourself with the DUD-E (Directory of Useful Decoys, Enhanced) data sets (http://dude.docking.org/), which contain known actives and inactives for 102 protein targets.The DUD-E sets are widely used in benchmarking studies that compare the performance of different virtual screening approaches (https://doi.org/10.1021/jm300687e).\n",
    "\n",
    "Go to the DUD-E target page (http://dude.docking.org/targets) and find muscle glycogen phosphorylase (Target Name: PYGM, PDB ID: 1c8k) from the target list.  Clicking the target name \"PYGM\" directs you to the page that lists various files (http://dude.docking.org/targets/pygm).  Download file \"**actives_final.ism**\", which contains the SMILES strings of known actives.  Rename the file name as \"**pygm_1c8k_actives.ism**\".  \\[Open the file in a text viewer/editor to check the format of this file\\].\n",
    "\n",
    "Identify the data what appropriate column names should be. \n",
    "\n",
    "1) Load the pygm_1c8k_actives.ism data into a DataFrame with appropriate column labels. \n",
    "2) Create a variable that has the number of rows in the DataFrame.\n",
    "3) Create a variable that has the number of columns in the DataFrame.\n",
    "4) Identify how many different structures are included in the dataset.\n",
    "5) Save this file locally as a .csv file with name: pygm_1c8k_actives_clean.csv without DataFrame index values.\n",
    "\n",
    "You will be using this .csv file in the next activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed277f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "\n",
    "colnames = ['smiles','DUD-E ID', 'CHEMBL_ID']\n",
    "df_pygm_actives = pd.read_csv(\"https://dude.docking.org/targets/pygm/actives_final.ism\", sep=\" \", names=colnames)\n",
    "# Create a variable that has the number of rows in the DataFrame.\n",
    "num_rows = df_pygm_actives.shape[0]  # or len(df_pygm_actives)\n",
    "# Create a variable that has the number of columns in the DataFrame.\n",
    "num_cols = df_pygm_actives.shape[1]  # or df_pygm_actives.columns.size\n",
    "\n",
    "# Identify number of unique SMILES strings in the df_pygm_actives DataFrame\n",
    "print(len(df_pygm_actives.smiles.unique()))\n",
    "# Save this file locally as a .csv file with name: pygm_1c8k_actives_clean.csv\n",
    "df_pygm_actives.to_csv(\"pygm_1c8k_actives_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e561db44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcd9963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OLCC2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
